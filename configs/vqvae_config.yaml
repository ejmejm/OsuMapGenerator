device: 'cuda:0'

# Logging
use_wandb: True
wandb_project: 'osu!-ai'

# Constants
beatmap_path: 'data/formatted_beatmaps/'
vocab_dir: 'preprocessing/vocab/'
model_save_path: 'models/large_model.pt'
model_vqvae_save_path: 'models/vqvae/large_model.pt'
output_dir: 'output/'

# Preprocessing
tokenizer_type: default # sentencepiece
spm_vocab_size: 1000 # Only used if using sentencepiece
relative_timing: False
break_length: 4 # How many beats without a hit object before breaks appear
include_audio: True
n_load_workers: 4

# Model
d_model: 512
d_hid: 2048
n_head: 4
n_encoder_layers: 2
n_decoder_layers: 2

max_src_len: 256
max_tgt_len: 1024
max_gen_len: 1024 # Max length for post-training generation

load_model: False

# Training
lr: 0.0001
epochs: 100
batch_size: 8
dropout: 0
eval_freq: 30000 # In number of samples

use_vqvae: True
n_down: 1
n_resblk: 3
codebook_size: 1024
dim_vq_latent: 1024
lambda_beta: 1

val_split: 0.1
test_split: 0.6

token_save_path: 'gen/tokens'
lambda_adv: 0.2

d_k: 64
d_v: 64
input_size: 5
lr_scheduler_e: 4000

token_length: 50

# Audio
segment_length: 23 # Audio segmentation size
prev_audio_segments_per_hitobject: 15 # How many previous audio segments to consider for the acoompanying audio signal of each hit object
next_audio_segments_per_hitobject: 0 # Same but for next


# Audio
segments_per_beat: 16 # Determines input to convolution
audio_tokens_per_segment: 1 # Determines convolution size
n_mel_bands: 80
sample_rate: 44100 # Currently not actually being used